{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train CNN-based DQN with History Buffer\n",
    "Largely inspired by the Atari paper by DeepMind, I want to build a deep Q network that uses CNN architecture to encode frames and feeds the fixed-length encoding to an RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gfootball.env as football_env\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from collections import deque\n",
    "import random\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "import copy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import custom modules from src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import dqn_utils as dq\n",
    "import training_ground as tg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### History buffer\n",
    "The `HistoryBuffer` class is already set up to handle the `(72, 96, 4)` pixel representation of the pitch. It does normalization and conversion to `float`. Picking an arbitrary number of frames to use for the agent's memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = dq.HistoryBuffer(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 4, 96, 72])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.get_tensor().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training strategy\n",
    "The `TrainingPlan` class schedules a series of progressively more difficult training scenarios. We just tell it how many of each difficulty to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = tg.TrainingPlan(basic_rounds=5,\n",
    "                           easy_rounds=10,\n",
    "                           medium_rounds=10,\n",
    "                           hard_rounds=10,\n",
    "                           full_match_rounds=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Architecture Specification\n",
    "Now we want to set up the DQN architecture. Starting with an encoder which will be applied to each observation (i.e. the $n$ most recent frames). This is where the Atari model inspiration really begins.\n",
    "\n",
    "* Inputs: $(n, C, L, W)$ tensor where $n$ is the history, $C$ the number of channels (4 here), and $L, W$ representing pitch dimensions\n",
    "* Output: $(n, d)$ tensor where $d$ is the dimensionality of the encoding\n",
    "\n",
    "This doesn't work super well for batched observations, but that's quick enough to handle downstream from this class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNEncoder(nn.Module):\n",
    "    def __init__(self, out_size):\n",
    "        super(CNNEncoder, self).__init__()\n",
    "        self.c1 = nn.Conv2d(4, 32, kernel_size=8, stride=4, padding=1)\n",
    "        self.c2 = nn.Conv2d(32, 64, kernel_size=5, stride=2, padding=1)\n",
    "        self.c3 = nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1)\n",
    "        self.c4 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.LeakyReLU()\n",
    "        self.linear = nn.Linear(1536, out_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h = self.relu(self.c1(x))\n",
    "        h = self.relu(self.c2(h))\n",
    "        h = self.relu(self.c3(h))\n",
    "        h = self.relu(self.c4(h))\n",
    "        flattened = h.flatten(-3)\n",
    "        out = self.relu(self.linear(flattened))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = CNNEncoder(512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 512])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc(history.get_tensor()).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the class which will use these encoders for each frame for each observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HistoryConvAgent(nn.Module):\n",
    "    def __init__(self, dropout_p = 0.1):\n",
    "        super(HistoryConvAgent, self).__init__()\n",
    "        self.encoder = CNNEncoder(out_size=256)\n",
    "        self.gru = nn.GRU(256, 256, num_layers=1, bidirectional=False, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.fc1 = nn.Linear(256, 256)\n",
    "        self.fc2 = nn.Linear(256, 18)\n",
    "        self.activation = nn.LeakyReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # batching doesn't play nicely here\n",
    "        if x.ndim == 4:\n",
    "            encoded = self.encoder(x)\n",
    "            _, gru_out = self.gru(encoded.unsqueeze(0))\n",
    "        else:\n",
    "            encoded = torch.stack([self.encoder(x[i]) for i in range(x.shape[0])])\n",
    "            _, gru_out = self.gru(encoded)\n",
    "        gru_out = self.dropout(gru_out.squeeze())\n",
    "        fc1_out = self.activation(self.fc1(gru_out))\n",
    "        fc2_out = self.activation(self.fc2(fc1_out))\n",
    "        return fc2_out\n",
    "    \n",
    "model = HistoryConvAgent()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non-batched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-3.6013e-04,  6.4678e-02,  5.2795e-02, -1.3404e-04,  2.1556e-02,\n",
       "         2.8254e-02,  2.3506e-02,  4.7141e-02,  1.6004e-02, -1.1682e-04,\n",
       "         4.5853e-02,  5.2699e-02, -3.2268e-05, -6.0494e-04,  6.6652e-02,\n",
       "         4.0843e-02, -4.8987e-04,  2.5698e-03], grad_fn=<LeakyReluBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(history.get_tensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 18])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.stack([history.get_tensor(), history.get_tensor() * 0.99])).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome - how many params are we working with?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "991986"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([np.prod(x.shape) for x in model.parameters()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just under a cool 1M\n",
    "\n",
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_net = copy.deepcopy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPSILON = 0.2\n",
    "EPS_DECAY = 0.999\n",
    "GAMMA = 0.99\n",
    "BATCH_SIZE = 32\n",
    "BUFFER_SIZE = 256\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "optim = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "replay_buffer = deque(maxlen=BUFFER_SIZE)\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "312dff8d722f46e78b7ed7a16008ca5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=43.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/opt/conda/lib/python3.7/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-40d74c40fc32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPSILON\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mGAMMA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     )\n\u001b[1;32m     19\u001b[0m     \u001b[0mepoch_rewards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperformance\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'reward'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/rl-football/src/dqn_utils.py\u001b[0m in \u001b[0;36mplay_round_with_history\u001b[0;34m(env, model, target_network, device, loss_fn, optimizer, sync_freq, replay_buffer, history_length, batch_size, epsilon, gamma, num_actions)\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0maction_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mreward_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0mstate2_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate2_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m             \u001b[0mdone_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdone_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epoch_losses = []\n",
    "epoch_rewards = []\n",
    "for match in tqdm_notebook(range(len(training.training_plan))):\n",
    "    env = training.get_next()\n",
    "    performance = dq.play_round_with_history(\n",
    "        env,\n",
    "        model=model, \n",
    "        target_network=target_net, \n",
    "        device=device, \n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=optim,\n",
    "        sync_freq=10,\n",
    "        replay_buffer=replay_buffer,\n",
    "        history_length=10,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epsilon=EPSILON,\n",
    "        gamma=GAMMA\n",
    "    )\n",
    "    epoch_rewards.append(performance['reward'])\n",
    "    epoch_losses.append(np.mean(performance['losses']))\n",
    "    EPSILON *= EPS_DECAY"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m56",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m56"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
